{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/ubuntu/nndl-project/')\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from src.models.voxnet import VoxNet\n",
    "from src.dataset import ModelNetDataset\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size' : 10,\n",
    "    'lr' : 0.01,\n",
    "    'gamma' : 0.5    \n",
    "}\n",
    "\n",
    "#Datasets\n",
    "\n",
    "metadata_path = '/home/ubuntu/nndl-project/data/modelnet10/metadata.parquet'\n",
    "num_workers = 1\n",
    "\n",
    "training_set = ModelNetDataset(metadata_path,split='train')\n",
    "validation_set = ModelNetDataset(metadata_path,split='test')\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = DataLoader(training_set, batch_size=config['batch_size'], shuffle=True, num_workers=num_workers)\n",
    "validation_loader = DataLoader(validation_set, batch_size=config['batch_size'], shuffle=False, num_workers=num_workers)\n",
    "\n",
    "model = VoxNet()\n",
    "\n",
    "# device\n",
    "device = \"cpu\"\n",
    "\n",
    "# LOSS FUNCTION\n",
    "# no parameters to tune here\n",
    "loss_c_fn = torch.nn.CrossEntropyLoss()\n",
    "loss_o_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "# OPTIMIZER\n",
    "# tune learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=config['lr'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False,  True, False, False, False, False, False, False, False, False])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    v_data = next(iter(validation_loader))\n",
    "\n",
    "    # get prediction and target\n",
    "    v_voxels,v_o_y,v_y = v_data\n",
    "    v_voxels = v_voxels.float().to(device)\n",
    "\n",
    "    # we move these to INTEGER label because the loss accepts it; \n",
    "    # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< FIX THIS IN DATASET SRC!\n",
    "    v_y, v_o_y = v_y.float().to(device).argmax(1), v_o_y.float().to(device).argmax(1)\n",
    "    v_o_y_pred, v_y_pred = model(v_voxels)\n",
    "    v_o_y_pred, v_y_pred = v_o_y_pred.to(device), v_y_pred.to(device)\n",
    "\n",
    "\n",
    "    # compute loss\n",
    "    loss_c = loss_c_fn(v_y_pred, v_y)\n",
    "    loss_o = loss_o_fn(v_o_y_pred,v_o_y)\n",
    "    vtotal_loss = (1-config['gamma'])*loss_c + config['gamma']*loss_o\n",
    "\n",
    "    # extract prediction from NN\n",
    "    true_orientation=v_o_y\n",
    "    predicted_orientation=v_o_y_pred.argmax(1)\n",
    "    correct_orientation_prediction = true_orientation == predicted_orientation\n",
    "\n",
    "    true_label=v_y\n",
    "    predicted_label=v_y_pred.argmax(1)\n",
    "    correct_label_prediction = true_label == predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "caf1c2fcf97217de91eafa76b907d50f9ea378f5ffbee7f571142d119bb6a771"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
